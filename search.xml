<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ReviewBoard+SVN实现code review]]></title>
    <url>%2F2019%2F07%2F28%2Fdocker-reviewboard%2F</url>
    <content type="text"><![CDATA[ReviewBoard简介ReviewBoard是个开源的、可扩展的、友好的基于Web的代码评审工具，是用Python框架Django开发的。ReviewBoard的官方网站：https://www.reviewboard.org，其title为： Take the pain out of code review | Review BoardTake the pain out of code review 可以翻译为：从代码评审的痛苦中解脱出来ReviewBoard的源码托管在GitHub上： https://github.com/reviewboard/reviewboardReviewBoard的源码也是通过ReviewBoard来进行评审的： https://reviews.reviewboard.org/ReviewBoard的DEMO： http://demo.reviewboard.org/，可以通过DEMO简单体验下ReviewBoard的基本使用ReviewBoard官方指南要了解ReviewBoard，最好的方式莫过于阅读官方指南： https://www.reviewboard.org/docs/，ReviewBoard的官方指南有：User Guide（用户指南）， Administration Guide（管理员指南），Web API Guide（Web API指南），Extending Review Board（扩展ReviewBoard）和 Frequently Asked Questions（常见问答FAQ）。用户指南的提纲：开始（包括代码评审的介绍、一般工作流、账户设置）、使用评审请求（评审请求的创建、修改、发布、关闭等）、评审、搜索、使用MarkDown。管理员指南的提纲：安装、升级、优化、管理员UI、配置、扩展和站点管理。Web API是RESTful架构，使得ReviewBoard可以用各种编程语言来集成。使用ReviewBoard进行代码评审代码评审（CodeReview）一般有两种形式：pre-commit-review，post-commit-review。pre-commit-review是指代码提交到代码库前进行代码评审；post-commit-review是指代码提交到代码库后进行代码评审。ReviewBoard同时支持以上两种形式，代码的评审主要通过ReviewRequest（评审请求）来进行的。其中pre-commit-review的工作流为：在代码修改后，提交人创建代码评审请求相应的评审人通过评审请求对代码进行评审，如果评审不通过，提交人可以更新该评审请求评审通过之后，提交人将代码提交至版比库当然，笔者始终认为代码评审的最好方式是提交前评审，这样能够很好的保证提交到版本库的代码都是经过评审的。Docker安装ReviewBoard官方文档ReviewBoard官网上docker-reviewboard页面：https://www.reviewboard.org/store/products/docker-reviewboard/GitHub上docker-reviewboard的源码：https://github.com/ikatson/docker-reviewboard/DockerHub上reviewboard的镜像：https://registry.hub.docker.com/u/ikatson/reviewboard/安装步骤123456789# Install postgresdocker run -d --name rb-postgres -e POSTGRES_USER=reviewboard postgres# Install memcacheddocker run --name rb-memcached -d -p 11211 sylvainlasnier/memcached# Run reviewboarddocker run -d --name reviewboard -v /var/www/reviewboard/:/var/www/ --link \rb-postgres:pg --link rb-memcached:memcached -p 8000:8000 ikatson/reviewboard访问ReviewBoard页面安装reviewboard-svn-hooks下载地址：http://pypi.python.org/pypi/reviewboard-svn-hooks解压并进入解压后的目录进行安装：python setup.py.install修改配置文件：vi /etc/reviewboard-svn-hooks/conf.ini12345678910111213141516171819[common]debug=0 # 是否记录debugging输出，0为不输出，1为输出[reviewboard]url=http://xxx.xxx.xx.xxx:8000 # reviewboard访问地址# reviewboard 的用户名密码username=adminpassword=xxxxxx[rule]min_ship_it_count=2 # 最少需要有几个ship itmin_expert_ship_it_count=2 # 最少需要有几个专家 ship itexperts=admin,test # 专家的reviewboard用户名，使用半角逗号分格# 指定必须review 的目录,默认为空，即表示强制 review 所有提交请求review_path= # 配置的路径则不会触发检测。 ignore_path =SVN hooks配置进入svn仓库的hooks目录，将pre-commit.tmpl更名为pre-commit，编辑pre-commit文件，删除所有内容，修改如下：1234567891011121314151617/home/svn/soft_2018/hooks # lspost-commit.tmpl post-revprop-change.tmpl pre-commit pre-lock.tmpl pre-unlock.tmplpost-lock.tmpl post-unlock.tmpl pre-commit.tmpl pre-revprop-change.tmpl start-commit.tmpl/home/svn/soft_2018/hooks # vi pre-commit#!/bin/shREPOS=&quot;$1&quot;EPOS=&quot;$1&quot;TXN=&quot;$2&quot;strict_review $REPOS $TXNexit $?客户端安装rbtools工具安装：pip install RBTools使用rbt命令前，需要在项目目录下新建一个配置文件.reviewboardrc，并进行配置：123REVIEWBOARD_URL=&quot;http://reivewboard_ip:8000&quot;REPOSITORY = &quot;soft_2018&quot;REPOSITORY_TYPE = &quot;svn&quot;执行rbt post 提交，在reviewboard平台上查看：可以看到summary为“add_test”的post已经提交成功了，点击进入review。常见问题1：唯一需要注意的事项是要在 log message 里写上符合正则表达式 r’review:([0-9]+)’ 的信息，比如 review:199 表示这次提交的变更对应 ID 为 199 的 review request，当 strict_review 这个 hook 检测到 review request 199 符合预设的条件后，就会放行让变更进入仓库。2：提交的文件没有满足配置的：”ship it“，enough of ship_it```12- 3：每个review的id只能使用一次，第二次使用则会出现如下错误：```reivew-id(54) is already used.4：提交时遇到如下错误：1&quot;Permission denied&quot;，解决方案：跟“/etc/reviewboard-svn-hooks”目录要有权限，加上权限重新提交后解决。]]></content>
      <categories>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>SVN</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker安装部署GitBook]]></title>
    <url>%2F2019%2F05%2F06%2Fdocker-gitbook%2F</url>
    <content type="text"><![CDATA[GitBook简介GitBook 是一个基于 Node.js 的命令行工具，可使用 Github/Git 和 Markdown 来制作精美的电子书，GitBook 并非关于 Git 的教程。GitBook支持输出多种文档格式：静态站点：GitBook默认输出该种格式，生成的静态站点可直接托管搭载Github Pages服务上；PDF：需要安装gitbook-pdf依赖；eBook：需要安装ebook-convert；单HTML网页：支持将内容输出为单页的HTML，不过一般用在将电子书格式转换为PDF或eBook的中间过程；JSON：一般用于电子书的调试或元数据提取。GitBook必备文件使用GitBook制作电子书，必备两个文件：README.md和SUMMARY.md。Docker安装GitBook搜索GitBook镜像12345[root@devops02 ~]# docker search --filter=stars=3 gitbookNAME DESCRIPTION STARS OFFICIAL AUTOMATEDfellah/gitbook GitBook 33 [OK]billryan/gitbook Docker for GitBook with Unicode support 14 [OK]gitbook/nuts Releases/downloads server with auto-updater … 5安装GitBook镜像官方镜像下载太慢的话可以使用国内的daocloud1[root@devops02 ~]# docker pull fellah/gitbook生成GitBook静态html文件/my_path下需要有README.md和SUMMARY.md两个文件。1[root@devops02 ~]# docker run -v /home/book:/srv/gitbook -v /home/book/html:/srv/html fellah/gitbook gitbook build . /srv/html用nginx做web服务来展示book搜索nginx镜像1[root@devops02 ~]# docker search --filter=stars=3 nginx安装nginx镜像1[root@devops02 ~]# docker run --name book -v /home/book/html:/usr/share/nginx/html -d -p 8080:80 nginxGitlab-CI配置pipline配置CI流程后，只需要提交代码到仓库，就可以自动编译部署。由于在一台服务器上，用了cp命令部署。如果gitlab-runner和gitbook项目在不同服务器，需用ssh和scp进行部署。1234567891011121314151617181920212223242526272829303132333435before_script: # 配置环境 - LANG=&quot;zh_CN.utf8&quot; - export LC_ALL=zh_CN.UTF-8stages: - deploy - build# deploydeploy: variables: CI_REPOSITORY_URL: http://$GIT_USERNAME:$GIT_PASSWORD@git.aioper.cn/$CI_PROJECT_PATH.git stage: deploy script: - echo &quot;start deploy&quot; - rm -rf $CI_PROJECT_NAME - echo &quot;git version&quot; &amp;&amp; git version - git config --global user.email $GIT_EMAIL - git clone $CI_REPOSITORY_URL - \cp -r $CI_PROJECT_NAME/* $BOOK_PATH - echo &quot;end deploy&quot;# gitbook build gitbook-build: stage: build script: - echo &quot;start gitbook build&quot; - docker -v - docker run -v /home/book:/srv/gitbook -v /home/book/html:/srv/html fellah/gitbook gitbook build . /srv/html - echo &quot;end gitbook build&quot; only: - master]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Django Signal 实现对模块的解耦]]></title>
    <url>%2F2019%2F04%2F30%2Fdjango-signal-usage%2F</url>
    <content type="text"><![CDATA[最近负责开发一个自动发现主机信息的应用。应用中数据流向复杂，处理逻辑冗余堆积。项目技术栈选择的是Django + Vuejs。前端使用 Webpack打包，模块化管理，主要是展示数据。后端涉及的模块多、处理规则多、数据表多，每次涉及之前功能修改时，都消耗大量时间进行code review。让我才意识到，在复杂应用中解耦模块非常重要。下面是一些调研和实践。1. 观察者模式2. Django Signal2.1 简单的例子2.2 从源码理解Django Signal处理逻辑3. 信号解耦、异步任务1. 观察者模式在实践中，我主要使用的是 Django Signal，实现对模块的解耦。Django Signal 是 Django 对观察者模式的实现和应用。因此，有必要先了解一下观察者模式。观察者模式是软件设计模式的一种。通常，大家会使用等式：发布 + 订阅 = 观察者模式。来表达对观察者模式的理解。实际上，这个等式并不完全正确。发布订阅模式与观察者模式区别：发布订阅模式的通信依赖于消息队列（RabbitMQ、RocketMQ、ActiveMQ、Kafka、ZeroMQ、MetaMq等）属于异步，观察者模式通常是同步的。发布订阅模式松散耦合，发布者和订阅者甚至所属不同应用；观察者模式所属一个应用。在实现上，观察者模式，需要维护一个订阅列表。当状态发生改变时，自动通知列表中的全部对象。2. Django SignalSignal 是 Django 框架中提供的一个信号分发器。发送器发送信号，通知一系列的接收器，从而触发接收器执行一些操作。需要注意的是，Django 信号是同步的。如果滥用，会影响到 Django 的处理效率。下面我会以 Django1.8.3为例，从一个使用案例出发，再到源码，介绍 Django 中 Signal 的实现方式。2.1 简单的例子这里有一个小需求：在Model表执行save后，触发一些执行逻辑。加载Signal myApp/init.py123456789101112131415161718192021222324252627# -*- coding: utf-8 -*-default_app_config = &apos;myApp.apps.MyAppConfig&apos;myApp/apps.py# -*- coding: utf-8 -*-from django.apps import AppConfigclass MyAppConfig(AppConfig): name = &apos;myApp&apos; def ready(self): import myApp.signals.handlers绑定信号处理函数myApp/signals/handlers.py# -*- coding: utf-8 -*-from django.dispatch import receiverfrom django.db.models.signals import post_savefrom myApp.models import MyModel@receiver(post_save, sender=MyModel, dispatch_uid=&quot;mymodel_post_save&quot;)def my_model_handler(sender, **kwargs): # 这里写 MyModel 执行 save 后的逻辑 pass2.2 从源码理解Django Signal处理逻辑上面的例子，使用了极少量的代码，就享受到了 Django 提供的信号处理机制所带来的便利。但是，如果仅仅停留在使用，你可能无法对 Django Signal有更深入的了解。下面，从源码来看看 Django Signal 的处理逻辑。声明信号Django 内置了大量 Model 相关的信号，可以直接使用。上面例子使用的信号 post_save ，就是 ModelSignal 类的一个实例，而 ModelSignal 又继承自 Signal 类。1234567891011django/db/models/signal.pyfrom django.dispatch import Signalclass ModelSignal(Signal): def connect(self, receiver, sender=None, weak=True, dispatch_uid=None): super(ModelSignal, self).connect( receiver, sender=sender, weak=weak, dispatch_uid=dispatch_uid )post_save = ModelSignal(providing_args=[&quot;instance&quot;, &quot;raw&quot;, &quot;created&quot;, &quot;using&quot;, &quot;update_fields&quot;], use_caching=True)注册信号处理函数Django 提供的 receiver 函数是一个装饰器，被修饰的函数作为参数注册到接收器对象列表。123456789101112131415161718192021django/dispatch/__init__.pyfrom django.dispatch.dispatcher import Signal, receiverdjango/dispatch/dispatcher.pydef receiver(signal, **kwargs): def _decorator(func): if isinstance(signal, (list, tuple)): for s in signal: s.connect(func, **kwargs) else: signal.connect(func, **kwargs) return func return _decoratordjango/dispatch/dispatcher.pyclass Signal(object): def __init__(self, providing_args=None, use_caching=False): self.receivers = [] def connect(self, receiver, sender=None, weak=True, dispatch_uid=None): self.receivers.append((lookup_key, receiver))发送信号在 save 完成之后，Django 会主动发出 post_save 信号；如果是自定义信号，那么需要自行触发。。123456789django/db/models/base.pyclass Model(six.with_metaclass(ModelBase)): # 触发 Model 相关的信号 def save_base(self, raw=False, force_insert=False, force_update=False, using=None, update_fields=None): # Signal that the save is complete signals.post_save.send(sender=origin, instance=self, created=(not updated), update_fields=update_fields, raw=raw, using=using)处理信号，实际上就是依次调用接受器列表中的函数。12345678910django/dispatch/dispatcher.pyclass Signal(object): def send(self, sender, **named): responses = [] for receiver in self._live_receivers(sender): response = receiver(signal=self, sender=sender, **named) responses.append((receiver, response)) return responses3. 信号解耦、异步任务在学习了观察者模式，了解 Django Signal 之后，就基本掌握了 Django 模块解耦的基础知识。接着，需要进一步明确模块之间的耦合机制，制定项目约定，就可以利落地实践了。梳理一下请求的处理链路：请求经过接入层、中间件处理之后，由 URL 分发器匹配到合适的处理模块，最终某个模块负责返回响应。各个模块连接数据库、消息队列、对象存储保存状态。每个模块包含四部分：AppLogic，模块的应用逻辑Signal，模块内置的信号SignalHandle，模块关注的信号处理句柄CeleryTasks，模块的异步任务模块与模块之前完全通过信号耦合：由于 Django Signal 是同步处理机制，为了支持异步处理，可以结合 Celery 和 RabbitMQ 进行实践。下面是一个信号处理异步逻辑的例子：1234567891011121314151617181920212223242526myApp/tasks.py# -*- coding: utf-8 -*-from celery import task@task(ignore_result=True)def my_task(instance): passmyApp/signals/handlers.py# -*- coding: utf-8 -*-from django.dispatch import receiverfrom django.db.models.signals import post_savefrom myApp.models import MyModelfrom myApp.tasks import my_task@receiver(post_save, sender=MyModel, dispatch_uid=&quot;mymodel_post_save&quot;)def my_model_handler(sender, **kwargs): instance = kwargs[&apos;instance&apos;] # 异步 my_task.apply_async(args=[instance]) # 同步 pass]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决rpm conflicts with file from package问题]]></title>
    <url>%2F2019%2F04%2F26%2Frpm-package-conflicts%2F</url>
    <content type="text"><![CDATA[123456[root@harbor opt]# rpm -ivh python27-2.7.9-1.x86_64.rpm准备中... ################################# [100%] file /usr/bin/python2.7 from install of python27-2.7.9-1.x86_64 conflicts with file from package python-2.7.5-76.el7.x86_64 file /usr/share/man/man1/python2.7.1.gz from install of python27-2.7.9-1.x86_64 conflicts with file from package python-2.7.5-76.el7.x86_64 file /usr/bin/python2.7-config from install of python27-2.7.9-1.x86_64 conflicts with file from package python-devel-2.7.5-76.el7.x86_64 file /usr/include/python2.7/pyconfig.h from install of python27-2.7.9-1.x86_64 conflicts with file from package python-devel-2.7.5-76.el7.x86_64方法一yum -y remove python-2.7.5-76.el7.x86_64卸载掉冲突的文件，安装新的文件。如果由于由于依赖关系导致要卸载很多软件，那可以优先考虑下一个方法。方法二rpm -ivh python27-2.7.9-1.x86_64.rpm –replacefiles安装的时候增加–replacefiles参数，但是不知道在yum里如何实现。–replacepkgs 强制重新安装已经安装的软件包–replacefiles 替换属于其它软件包的文件rpm -e –nodeps python27-2.7.9-1.x86_64.rpm 强制删除包]]></content>
      <categories>
        <category>Python</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab-CI持续集成实践]]></title>
    <url>%2F2019%2F03%2F07%2Fgitlab-ci-practice%2F</url>
    <content type="text"><![CDATA[持续集成是一种软件开发实践，即团队开发成员经常集成它们的工作，通过每个成员每天至少集成一次，也就意味着每天可能会发生多次集成。每次集成都通过自动化的构建（包括编译，发布，自动化测试）来验证，从而尽早地发现集成错误。gitlab一般用Gitlab-CI，而github一般用jenkins，主要功能是在你提交或merge代码到仓库后，自动执行一些你定义好的命令， 比如安装依赖、单元测试、pep8检查、甚至还可以自动部署到生成环境。前段时间自己给当前做的项目加上了gitlab-ci,实现的主要功能是提交代码后自动检测安装依赖有没有问题，单元测试能不能通过， pep 8 规范检查是否合格，有一项不合格就会在提交的分支或merge后面有个显目的红叉， 全通过的话则是一个赏心悦目的绿色对勾。GitLab简单原理图安装和配置Runnerpipeline 配置pep 8GitLab简单原理图安装和配置Runner首先， gitlab ci 需要单独部署在一台服务器上来运行， 对应的程序是GitLab Runner,在ubuntu和centos上安装都是先根据一个shell脚本安装各种依赖， 然后再执行安装程序。123456# For Debian/Ubuntu $ curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-ci-multi-runner/script.deb.sh | sudo bash $ sudo apt-get install gitlab-ci-multi-runner # For CentOS $ curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-ci-multi-runner/script.rpm.sh | sudo bash $ sudo yum install gitlab-ci-multi-runner为了能够让GitLab Runner 能够连接到我们的项目上需要注册操作：sudo gitlab-runner register然后根据提示输入配置信息（这些信息可以在项目的gitlab网站的CI/CD 配置里找到， 需要master权限）1234567891011121314151617181920Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com ) https://gitlab.com //项目gitlab的根域名， 一般公司都会部署自己内部使用的gitlab Please enter the gitlab-ci token for this runner xxx // gitlab token, 每个项目都不一样 Please enter the gitlab-ci description for this runner [hostame] my-runner // 项目描述， 起个名称 Please enter the gitlab-ci tags for this runner (comma separated): my-tag,another-tag // 给该 Runner 指派 tags, 稍后也可以在 GitLab&apos;s UI 修改, 这里也可以直接回车， 使用默认值 Whether to run untagged jobs [true/false]: [false]: true // 选择 Runner 是否接收未指定 tags 的任务（默认值：false）， 稍后可以在 GitLab&apos;s UI 修改 Whether to lock Runner to current project [true/false]: [true]: false // 该runner是否只能运行当前指定项目（根据token来判断的），默认值：true： Please enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell: shell // 选择runner的类型， 这里用shell就好配置完成， sudo gitlab-runner list 可以查看当前runner的状态。pipeline 配置GitLab Runner 启动成功后接下来就是在你的项目里配置gitlab ci要干哪些事情了， 在项目的根目录新建一个.gitlab-ci.yml 文件，在里边配置代码commit后gitlab ci要干的事情。一个简单的示例如下：12345678910111213141516# 定义 stages stages: - build - test # 定义 job job1: stage: test script: - echo &quot;I am job1&quot; - echo &quot;I am in test stage&quot; # 定义 job job2: stage: build script: - echo &quot;I am job2&quot; - echo &quot;I am in build stage&quot;执行顺序如下：stages里的stage按顺序执行， 如果有一个stage执行失败， 结束， 不再往下执行。执行每个stage时，stage里的job并行执行， 所有job都执行成功该stage才算成功， 有一个失败的话该stage执行失败， 结束。此外，还有连个非常有用的选项——before_script 和 after_script, 分别对应着每个job执行前后要运行的额外代码。更多的配置选项可以看gitlab ci的官方文档pep 8当多人参与一个项目时， 统一代码规范就很重要。 python一般用的是pep 8， 用flake 8 可以很方便做到。安装pip install flake8 pep8-naming在项目根目录下新建一个.flake8配置文件配置文件内容大概如下（不要出现中文， 后面的注释是为了便于读者理解额外添加的）：12345678910111213141516171819202122[flake8] ignore = W292 W391 E126 W291 N805 // 忽略的格式类型 exclude = // 忽略的文件、文件夹 *migrations*, # python related *.pyc, .git, __pycache__, *.conf, *.md, config* *settings* manage.py gold/vulpo/* max-line-length=125 // 单行最大字数 max-complexity=16 // 复杂度上限 format=pylint show_source = True statistics = True count = True当然， 记得在.gitlab-ci.yml 中添加一个执行pep 8 检查的job：12345pep8_test: stage: pep8 script: - flake8 gold # allow_failure: true // 有追求的程序员当然不会允许pep 8 检查不通过]]></content>
      <categories>
        <category>CI/CD</category>
      </categories>
      <tags>
        <tag>CI/CD</tag>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gerrit安装部署]]></title>
    <url>%2F2019%2F02%2F22%2Fgerrit-deploy%2F</url>
    <content type="text"><![CDATA[Gerrit简介Gerrit，一种免费、开放源代码的代码审查软件，使用网页界面。利用网页浏览器，同一个团队的软件程序员，可以相互审阅彼此修改后的程序代码，决定是否能够提交，退回或者继续修改。一、创建gerrit用户123456789[root@devops02 ~]# adduser gerrit -mYou have mail in /var/spool/mail/root[root@devops02 ~]# passwd gerritChanging password for user gerrit.New password:BAD PASSWORD: The password is shorter than 8 charactersRetype new password:passwd: all authentication tokens updated successfully.[root@devops02 ~]#二、安装gerrit12345678[root@devops02 ~]# su - gerritLast login: Wed Feb 20 15:05:42 CST 2019 on pts/0[gerrit@devops02 ~]$ pwd/home/gerrit[gerrit@devops02 ~]$ lltotal 72520-rw-r--r--. 1 root root 74258227 Feb 20 15:09 gerrit-2.16.5.war[gerrit@devops02 ~]$ java -jar gerrit-2.16.5.war init -d ~/gerrit_site三、安装步骤12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788Using secure store: com.google.gerrit.server.securestore.DefaultSecureStore[2019-02-20 15:16:04,189] [main] INFO com.google.gerrit.server.config.GerritServerConfigProvider : No /home/gerrit/gerrit_site/etc/gerrit.config; assuming defaults*** Gerrit Code Review 2.16.5****** Git Repositories***Location of Git repositories [git]:*** SQL Database***Database server type [h2]:*** Index***Type [lucene/?]:*** User Authentication***Authentication method [openid/?]: httpGet username from custom HTTP header [y/N]?SSO logout URL :Enable signed push support [y/N]?*** Review Labels***Install Verified label [y/N]?*** Email Delivery***SMTP server hostname [localhost]:SMTP server port [(default)]:SMTP encryption [none/?]:SMTP username :*** Container Process***Run as [gerrit]:Java runtime [/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64/jre]:Copy gerrit-2.16.5.war to /home/gerrit/gerrit_site/bin/gerrit.war [Y/n]?Copying gerrit-2.16.5.war to /home/gerrit/gerrit_site/bin/gerrit.war*** SSH Daemon***Listen on address [*]:Listen on port [29418]:Generating SSH host key ... rsa... ed25519... ecdsa 256... ecdsa 384... ecdsa 521... done*** HTTP Daemon***Behind reverse proxy [y/N]?Use SSL (https://) [y/N]?Listen on address [*]:Listen on port [8080]: 8081Canonical URL [http://devops02:8081/]:*** Cache****** Plugins***Installing plugins.Install plugin codemirror-editor version v2.16.5 [y/N]?Install plugin commit-message-length-validator version v2.16.5 [y/N]?Install plugin download-commands version v2.16.5 [y/N]?Install plugin hooks version v2.16.5 [y/N]?Install plugin replication version v2.16.5 [y/N]?Install plugin reviewnotes version v2.16.5 [y/N]?Install plugin singleusergroup version v2.16.5 [y/N]?Initializing plugins.No plugins found with init steps.Initialized /home/gerrit/gerrit_siteInit complete, reindexing projects with: reindex --site-path /home/gerrit/gerrit_site --threads 1 --iReindexing projects: 100% (2/2)Reindexed 2 documents in projects index in 0.1s (38.5/s)四、nginx安装配置五、创建登陆认证文件12345[gerrit@devops02 ~]$ htpasswd -c /home/gerrit/gerrit.password adminNew password:Re-type new password:Adding password for user admin[gerrit@devops02 ~]$htpasswd是apache的一个模块，需要先安装apache服务，通过以下任意一个安装1root@devops02 ~]# yum install httpd-tools //单独安装部分工具1[root@devops02 ~]# yum install httpd //安装完整的apache六、设置权限12[gerrit@devops02 ~]$ cd /home/[gerrit@devops02 home]$ chmod 755 gerrit/七、配置gerrit.config1234567891011121314151617[gerrit@devops02 home]$ cd /home/gerrit/gerrit_site/etc/[gerrit@devops02 etc]$ lltotal 52-rw-rw-r--. 1 gerrit gerrit 716 Feb 20 15:22 gerrit.configdrwxrwxr-x. 2 gerrit gerrit 4096 Feb 20 15:22 mail-rw-------. 1 gerrit gerrit 71 Feb 20 15:17 secure.config-rw-------. 1 gerrit gerrit 288 Feb 20 15:18 ssh_host_ecdsa_384_key-rw-r--r--. 1 gerrit gerrit 233 Feb 20 15:18 ssh_host_ecdsa_384_key.pub-rw-------. 1 gerrit gerrit 365 Feb 20 15:18 ssh_host_ecdsa_521_key-rw-r--r--. 1 gerrit gerrit 281 Feb 20 15:18 ssh_host_ecdsa_521_key.pub-rw-------. 1 gerrit gerrit 227 Feb 20 15:18 ssh_host_ecdsa_key-rw-r--r--. 1 gerrit gerrit 189 Feb 20 15:18 ssh_host_ecdsa_key.pub-rw-------. 1 gerrit gerrit 419 Feb 20 15:18 ssh_host_ed25519_key-rw-r--r--. 1 gerrit gerrit 109 Feb 20 15:18 ssh_host_ed25519_key.pub-rw-------. 1 gerrit gerrit 1675 Feb 20 15:18 ssh_host_rsa_key-rw-r--r--. 1 gerrit gerrit 409 Feb 20 15:18 ssh_host_rsa_key.pub[gerrit@devops02 etc]$ vi gerrit.config1234567891011121314151617181920212223242526272829[gerrit] basePath = git serverId = 280a982e-5d60-49c4-95f6-0b944f4b1c5e canonicalWebUrl = http://192.168.51.36:81/[database] type = h2 database = /home/gerrit/gerrit_site/db/ReviewDB[container] javaOptions = &quot;-Dflogger.backend_factory=com.google.common.flogger.backend.log4j.Log4jBackendFactory#getInstance&quot; javaOptions = &quot;-Dflogger.logging_context=com.google.gerrit.server.logging.LoggingContext#getInstance&quot; user = gerrit javaHome = /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64/jre[index] type = LUCENE[auth] type = HTTP[oauth] allowEditFullName = true allowRegisterNewEmail = true[receive] enableSignedPush = false[sendemail] enable = false[sshd] listenAddress = *:29418[httpd] listenUrl = http://*:8081/[cache] directory = cache八、重启gerrit123[gerrit@devops02 etc]$ /home/gerrit/gerrit_site/bin/gerrit.sh restartStopping Gerrit Code Review: OKStarting Gerrit Code Review: OK九、启动nginx1[root@devops02 ~]# /usr/local/nginx/sbin/nginx十、访问1http://192.168.81.163:81 //根据实际情况修改IP和端口]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): 没有那个文件或目录]]></title>
    <url>%2F2019%2F02%2F14%2Fsetlocale-warning%2F</url>
    <content type="text"><![CDATA[SSH登陆linux服务器，显示警告: setlocale: LC_CTYPE: 无法改变区域选项 (UTF-8)（warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory）。解决方案在123```LC_ALL=zh_CN.UTF_8LANG=zh_CN.UTF_8下次SSH登陆的时候，就不会出现如上警告了。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos-fastdfs-nginx]]></title>
    <url>%2F2019%2F01%2F22%2Fcentos-fastdfs-nginx%2F</url>
    <content type="text"><![CDATA[1. FastDFS介绍FastDFS是一个开源的分布式文件系统，她对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。FastDFS服务端有两个角色：跟踪器（tracker）和存储节点（storage）。跟踪器主要做调度工作，在访问上起负载均衡的作用。存储节点存储文件，完成文件管理的所有功能：存储、同步和提供存取接口，FastDFS同时对文件的meta data进行管理。所谓文件的meta data就是文件的相关属性，以键值对（key value pair）方式表示，如：width=1024，其中的key为width，value为1024。文件meta data是文件属性列表，可以包含多个键值对。FastDFS系统结构如下图所示：跟踪器和存储节点都可以由一台或多台服务器构成。跟踪器和存储节点中的服务器均可以随时增加或下线而不会影响线上服务。其中跟踪器中的所有服务器都是对等的，可以根据服务器的压力情况随时增加或减少。为了支持大容量，存储节点（服务器）采用了分卷（或分组）的组织方式。存储系统由一个或多个卷组成，卷与卷之间的文件是相互独立的，所有卷 的文件容量累加就是整个存储系统中的文件容量。一个卷可以由一台或多台存储服务器组成，一个卷下的存储服务器中的文件都是相同的，卷中的多台存储服务器起 到了冗余备份和负载均衡的作用。在卷中增加服务器时，同步已有的文件由系统自动完成，同步完成后，系统自动将新增服务器切换到线上提供服务。当存储空间不足或即将耗尽时，可以动态添加卷。只需要增加一台或多台服务器，并将它们配置为一个新的卷，这样就扩大了存储系统的容量。FastDFS中的文件标识分为两个部分：卷名和文件名，二者缺一不可。上传文件交互过程：client询问tracker上传到的storage，不需要附加参数；tracker返回一台可用的storage；client直接和storage通讯完成文件上传。下载文件交互过程：client询问tracker下载文件的storage，参数为文件标识（卷名和文件名）；tracker返回一台可用的storage；client直接和storage通讯完成文件下载。需要说明的是，client为使用FastDFS服务的调用方，client也应该是一台服务器，它对tracker和storage的调用均为服务器间的调用。2. FastDFS单机部署2.1 准备系统:CentOS7安装包:1234567891011[root@fastdfs fastdfs5.11]# pwd/home/fastdfs5.11[root@fastdfs fastdfs5.11]# lltotal 1996-rwxr-xr-x. 1 root root 424689 Nov 8 2017 fastdfs-5.11.zip-rwxr-xr-x. 1 root root 22192 Nov 8 2017 fastdfs-nginx-module-master.zip-rwxr-xr-x. 1 root root 3027 Jan 21 12:26 fastdfs_install.sh-rwxr-xr-x. 1 root root 478888 Nov 8 2017 libfastcommon-1.0.36.zip-rwxr-xr-x. 1 root root 911509 Nov 8 2017 nginx-1.10.3.tar.gz``` ### 2.2 安装依赖包#安装依赖软件yum install make cmake gcc gcc-c++1### 2.3 安装libfastcommoncd /home/fastdfs5.11/unzip libfastcommon-1.0.36.zipmkdir -p usr/local/fastdfsmv libfastcommon-1.0.36 /usr/local/fastdfs/libfastcommoncd /usr/local/fastdfs/libfastcommon./make.sh./make.sh install1### 2.4 安装fastdfscd /home/fastdfs5.11/unzip fastdfs-5.11.zipmv fastdfs-5.11 /usr/local/fastdfs/cd /usr/local/fastdfs/fastdfs-5.11./make.sh./make.sh install123456安装好之后，在/usr/bin目录下，可以看fdfs开头的命令工具&gt; FastDFS安装完成之后，所有配置文件在/etc/fdfs目录下， tracker需要tracker.conf配置文件， storage需要storage.conf配置文件。 ### 2.5 配置trackercd /etc/fdfs/cp tracker.conf.sample tracker.confvi tracker.conf设置tracker的数据文件和日志目录（需手动创建）base_path=/fastdfs/tracker设置http端口号http.server_port=88881234使用&lt;font color=&quot;#FF00FF&quot;&gt;fdfs_trackerd /etc/fdfs/tracker.conf start&lt;/font&gt;尝试启动tracker检查是否启动[root@fastdfs ~]# ps -ef | grep tracker[root@fastdfs ~]# ps -ef | grep fdfsroot 24412 1 0 Jan21 ? 00:00:12 /usr/bin/fdfs_trackerd /etc/fdfs/tracker.confroot 129129 128507 0 16:39 pts/2 00:00:00 grep –color=auto fdfs1### 2.6 配置storagecd /etc/fdfs/cp storage.conf.sample storage.confvi storage.conf设置storage的数据和日志文件存储根目录base_path=/fastdfs/storage第一个存储目录，第二个存储目录起名为：store_path1=xxx，其它存储目录名依次类推…store_path0=/fastdfs/storage存储路径个数，需要和store_path个数匹配store_path_count=1tracker服务器IP和端口，有多个则添加多行tracker_server=192.168.51.36:22122123使用&lt;font color=&quot;#FF00FF&quot;&gt;fdfs_storaged /etc/fdfs/storage.conf start&lt;/font&gt;尝试启动storage检查是否启动[root@fastdfs ~]# ps -ef | grep fdfsroot 24412 1 0 Jan21 ? 00:00:12 /usr/bin/fdfs_trackerd /etc/fdfs/tracker.confroot 26683 1 0 Jan21 ? 00:00:12 /usr/bin/fdfs_storaged /etc/fdfs/storage.confroot 129129 128507 0 16:39 pts/2 00:00:00 grep –color=auto fdfs12345在任一storage节点上使用如下命令查看集群的状态信息：&gt;fdfs_monitor /etc/fdfs/storage.conf 如果出现ip_addr = Active，则表明storage服务器已经登记到tracker服务器，如下：server_count=1, server_index=0tracker server is 192.168.51.36:22122group count: 1Group 1:group name = group1disk total space = 97228 MBdisk free space = 90266 MBtrunk free space = 0 MBstorage server count = 1active server count = 1storage server port = 23000storage HTTP port = 8888store path count = 1subdir count per path = 256current write server index = 0current trunk file id = 0Storage 1: id = 192.168.51.36 ip_addr = 192.168.51.36 (fastdfs) ACTIVE 123### 2.7 在storage上安装nginx&gt; 注意： fastdfs-nginx-module模块只需要安装到storage上。cd /home/fastdfs5.11/unzip fastdfs-nginx-module-master.zipmv fastdfs-nginx-module-master /usr/local/src/tar -zxvf nginx-1.10.3.tar.gzcd nginx-1.10.3./configure –prefix=/usr/local/nginx –add-module=/usr/local/src/fastdfs-nginx-module-master/src/make &amp;&amp; make install1如下结果则表示安装成功[root@fastdfs fastdfs-nginx-module-master]# /usr/local/nginx/sbin/nginx -Vnginx version: nginx/1.10.3built by gcc 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC)configure arguments: –prefix=/usr/local/nginx –add-module=/usr/local/src/fastdfs-nginx-module-master/src1### 2.8 配置clientcd /etc/fdfs/cp client.conf.sample client.confvi client.conf#数据和日志文件存储根目录base_path=/fastdfs/trackertracker_server=192.168.51.36:22122http.tracker_server_port=8888123```[root@fastdfs fastdfs5.11]# fdfs_upload_file /etc/fdfs/client.conf /home/fastdfs5.11/saml.pnggroup1/M00/00/00/wKgzJFxG4LaAH8UHAAL3GebUIgk668.png2.9 配置fastdfs-nginx-module和nginx12345678910111213141516171819202122232425cp /usr/local/src/fastdfs-nginx-module-master/src/mod_fastdfs.conf /etc/fdfs/cd /etc/fdfs/vi mod_fastdfs.conf# 保存日志目录base_path=/fastdfs# tracker服务器IP和端口，有多个按行添加tracker_server=192.168.51.36:22122# storage服务器的端口号storage_server_port=23000 # 当前服务器的group名group_name=group1 # 文件url中是否有group名url_have_group_name = true # 存储路径个数，需要和store_path个数匹配store_path_count=1 # 存储路径store_path0=/fastdfs/storage # 设置组的个数，设置为0则为单组group_count = 1 #在文件末尾加上[group1]group_name=group1storage_server_port=23000store_path_count=1store_path0=/fastdfs/storagenginx.conf配置vhost12345cd /home/fastdfs5.11/conf/cp http.conf mime.types /etc/fdfs/vi /usr/local/nginx/conf/nginx.conf#在http里添加include vhost/*.conf;配置storage.conf1234567891011121314151617vi /usr/local/nginx/conf/vhost/storage.conf# storage.confserver &#123; listen 8888 ; server_name 192.168.51.36 ; location / &#123; root html; index index.html index.htm; &#125; location ~/group[0-9]/M00 &#123; alias /fastdfs/storage/data/; ngx_fastdfs_module; &#125;&#125;启动nginx:1/usr/local/nginx/sbin/nginx2.10 关闭selinux、firewalld12345vi /etc/selinux/configSELINUX=disabled# systemctl stop firewalld.service# systemctl disable firewalld.service拼接上面文件中生成的字符串，进行url访问：1http://192.168.51.36:8888/group1/M00/00/00/wKgzJFxG4LaAH8UHAAL3GebUIgk668.png后续有时间写一个一键安装FastDFS和配置的脚本。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Protocol Buffers官方文档(开发指南)]]></title>
    <url>%2F2019%2F01%2F22%2Fprotocol-buffers%2F</url>
    <content type="text"><![CDATA[本文是对官方文档的翻译，然后截取了一篇非常优秀的文章片段来帮助理解，本人英文水平有限，基本都是直译，如果有不理解的地方请参考英文官方文档，参考的文章链接在文章末尾protocal buffers简介protocol buffer是google的一个开源项目,它是用于结构化数据串行化的灵活、高效、自动的方法，例如XML，不过它比xml更小、更快、也更简单。你可以定义自己的数据结构，然后使用代码生成器生成的代码来读写这个数据结构。你甚至可以在无需重新部署程序的情况下更新数据结构protocal buffers是如何工作的在.proto文件定义消息，message是.proto文件最小的逻辑单元，由一系列name-value键值对构成。下面的.proto文件定义了一个”人”的消息：123456789101112131415161718message Person &#123; required string name = 1; required int32 id = 2; optional string email = 3; enum PhoneType &#123; MOBILE = 0; HOME = 1; WORK = 2; &#125; message PhoneNumber &#123; required string number = 1; optional PhoneType type = 2 [default = HOME]; &#125; repeated PhoneNumber phone = 4;&#125;message消息包含一个或多个编号唯一的字段，每个字段由字段限制,字段类型,字段名和编号四部分组成，字段限制分为：optional(可选的)、required(必须的)以及repeated(重复的)。定义好消息后，使用ProtoBuf编译器生成C++对应的.h和.cc文件，源文件提供了message消息的序列化和反序列化等方法：123456789101112# 序列化数据Person person;person.set_name(&quot;John Doe&quot;);person.set_id(1234);person.set_email(&quot;jdoe@example.com&quot;);fstream output(&quot;myfile&quot;, ios::out | ios::binary);person.SerializeToOstream(&amp;output);# 反序列化数据fstream input(&quot;myfile&quot;, ios::in | ios::binary);Person person;person.ParseFromIstream(&amp;input);cout &lt;&lt; &quot;Name: &quot; &lt;&lt; person.name() &lt;&lt; endl;cout &lt;&lt; &quot;E-mail: &quot; &lt;&lt; person.email() &lt;&lt; endl;为什么不直接使用XML同XML相比，Protobuf的优势在于高性能，它以高效的二进制存储方式比XML小3到10倍，快20到100倍，原因在于：ProtoBuf序列化后所生成的二进制消息非常紧凑ProtoBuf封解包过程非常简单Protobuf序列化Varint简介Varint 是一种紧凑的表示数字的方法。它用一个或多个字节来表示一个数字，值越小的数字使用越少的字节数。这能减少用来表示数字的字节数。比如对于int32类型的数字，一般需要4个byte来表示，但是采用Varint对于很小的int32类型的数字，则可以用1个byte来表示。当然凡事都有好的也有不好的一面，采用Varint表示法，大的数字则需要5个byte来表示。从统计的角度来说，一般不会所有的消息中的数字都是大数，因此大多数情况下，采用Varint后可以用更少的字节数来表示数字信息。Varint格式Varint中的每个byte的最高位bit有特殊的含义，如果该位为1，表示后续的byte也是该数字的一部分，如果该位为0则结束，其他的7个bit都用来表示数字。因此小于128的数字都可以用一个byte表示，大于128的数字会用两个字节来表示。Varint编解码比如数值300用Varint来表示就是：1010 1100 0000 0010。下图演示了Google Protocol Buffer解析Varint表示的300的过程，由于Google Protocol Buffer采用小端字节序，所以实际存储的字节顺序是反过来的：###Google Protocol Buffer序列化消息经过序列化后会成为一个二进制数据流，该流中的数据为一系列的Key-Value对。如下图所示：采用这种Key-Pair结构无需使用分隔符来分割不同的 Field。对于可选的Field，如果消息中不存在该Field，那么在最终的Message Buffer中就没有该Field，这些特性都有助于节约消息本身的大小。Key 用来标识具体的Field，在解包的时候ProtoBuf根据Key就可以知道相应的Value应该对应于消息中的哪一个Field。Key由字段的编号和字段的线性传输类型构成&gt; (field_number &lt;&lt; 3) | wire_typewire_typeMeaningUsedFor0Varintint32, int64, uint32, uint64, sint32, sint64, bool, enum164-bitfixed64, sfixed64, double2Length-delimistring, bytes, embedded messages, packed repeated fields3Start groupGroups (deprecated)4End groupGroups (deprecated)532-bitfixed32, sfixed32, floatGoogle Protocol Buffer采用zigzag编码来用无符号数来表示有符号数字，zigzag采用正数和负数交错的方式来同时表示无符号数来表示有符号数字，如图所示：使用zigzag编码，绝对值小的数字，无论正负都可以采用较少的byte来表示，充分利用了Varint这种技术。其他的数据类型，比如字符串等则采用类似数据库中的varchar的表示方法，即用一个varint表示长度，然后将其余部分紧跟在这个长度部分之后即可。ProtoBuf编码与XML编码对比消息定义如下：1234567package lm; message helloworld&#123; required int32 id = 1; // ID required string str = 2; // str optional int32 opt = 3; //optional field&#125;假设有一条123```08 65 12 06 48 65 6C 6C 6F 77``` 而如果用XML，则类似这样：31 30 31 3C 2F 69 64 3E 3C 6E 61 6D 65 3E 68 656C 6C 6F 3C 2F 6E 61 6D 65 3E 3C 2F 68 65 6C 6C6F 77 6F 72 6C 64 3E一共 55 个字节，这些奇怪的数字需要稍微解释一下，其含义用 ASCII 表示如下：101hello`ProtoBuf封装包首先我们来了解一下XML的封解包过程。XML需要从文件中读取出字符串，再转换为XML文档对象结构模型。之后再从XML文档对象结构模型中读取指定节点的字符串，最后再将这个字符串转换成指定类型的变量，这个过程非常复杂。其中将XML文件转换为文档对象结构模型的过程通常需要完成词法文法分析等大量消耗 CPU 的复杂计算。反观Protobuf，它只需要简单地将一个二进制序列按照指定的格式读取到C++对应的结构类型中就可以了。从上一节的描述可以看到，消息的解码过程也可以通过几个位移操作组成的表达式计算即可完成，速度非常快。上面例子中，Protobuf解包helloworld消息的过程可以用下图表示：整个解析过程需要Protobuf本身的框架代码和由Protobuf编译器生成的代码共同完成。其中Message以及Message_lite作为通用的流程框架，CodedInputStream、WireFormatLite提供了对二进制数据的解码功能，而且Protobuf的解码可以通过几个简单的数学运算完成，无需复杂的词法语法分析，因此图中ReadTag()等方法都非常快。相对于XML的解析，整个调用路径上的其他类和方法都非常简单，这也就是ProtoBuf封解包速度迅速的原因。参考资料Google Protocal Buffer 的使用和原理]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git最佳实践-分支管理]]></title>
    <url>%2F2018%2F12%2F19%2Fgit-operation%2F</url>
    <content type="text"><![CDATA[1.引言git 和 svn 的一个显著区别就是提供更丰富的分支特性，我们今天就要说一下如何管理这些分支。关于 git 的分支管理，Vincent Driessen 有一篇文章说的非常好，地址在参考[1]。我这里主要就是参考他的文章。2. 总览git 的分支整体预览图如下。&nbsp;&nbsp;&nbsp;从上图可以看到主要包含下面几个分支：&nbsp;master: 主分支，主要用来版本发布。develop：日常开发分支，该分支正常保存了开发的最新代码。feature：具体的功能开发分支，只与 develop 分支交互。release：release 分支可以认为是 master 分支的未测试版。比如说某一期的功能全部开发完成，那么就将 develop 分支合并到 release 分支，测试没有问题并且到了发布日期就合并到 master 分支，进行发布。hotfix：线上 bug 修复分支。除此之后还可以有 fast-track 等分支。&nbsp;3. 主分支&nbsp;主分支包括 master 分支和 develop 分支。master 分支用来发布，HEAD 就是当前线上的运行代码。develop 分支就是我们的日常开发。使用这两个分支就具有了最简单的开发模式：develop 分支用来开发功能，开发完成并且测试没有问题则将 develop 分支的代码合并到 master 分支并发布。&nbsp;&nbsp;&nbsp;这引入了几个问题：&nbsp;develop 分支只有发布完了才能进行下一个版本开发，开发会比较缓慢。线上代码出现 bug 如何进行 bug 修复。带着这两个问题往下看。&nbsp;4. 辅助分支&nbsp;主要介绍的辅助分支如下：&nbsp;feature 分支release 分支hotfix 分支通过这些分支，我们可以做到：团队成员之间并行开发，feature track 更加容易，开发和发布并行以及线上问题修复。&nbsp;4.1 Feature 分支&nbsp;feature 分支用来开发具体的功能，一般 fork 自 develop 分支，最终可能会合并到 develop 分支。比如我们要在下一个版本增加功能1、功能2、功能3。那么我们就可以起三个feature 分支：feature1，feature2，feature3。（feature 分支命名最好能够自解释，这并不是一种好的命名。）随着我们开发，功能1和功能2都被完成了，而功能3因为某些原因完成不了，那么最终 feature1 和 feature2 分支将被合并到 develop 分支，而 feature3 分支将被干掉。&nbsp;&nbsp;&nbsp;我们来看几个相关的命令。&nbsp;从 develop 分支建一个 feature 分支，并切换到 feature 分支&nbsp;$&nbsp;git&nbsp;checkout&nbsp;-b&nbsp;myfeature developSwitched&nbsp;to&nbsp;a&nbsp;new&nbsp;branch&nbsp;“myfeature”&nbsp;合并feature 分支到 develop&nbsp;$&nbsp;git checkout developSwitched&nbsp;to&nbsp;branch&nbsp;‘develop’$&nbsp;git&nbsp;merge&nbsp;–no-ff myfeatureUpdating&nbsp;ea1b82a..05e9557(Summary of&nbsp;changes)$&nbsp;git&nbsp;branch&nbsp;-d&nbsp;myfeatureDeleted branch&nbsp;myfeature$&nbsp;git push origin&nbsp;develop&nbsp;上面我们 merge 分支的时候使用了参数&nbsp;–no-ff，ff 是fast-forward&nbsp;的意思，–no-ff就是禁用fast-forward。关于这两种模式的区别如下图。（可以使用 sourceTree 或者命令git log –graph查看。）&nbsp;&nbsp;&nbsp;看了上面的图，那么使用非fast-forward模式来 merge 的好处就不言而喻了：我们知道哪些 commit 是某些 feature 相关的。虽然 git merge 的时候会自动判断是否使用fast-farward模式，但是有时候为了更明确，我们还是要加参数–no-ff或者–ff。&nbsp;4.2 Release 分支&nbsp;release 分支在我看来是 pre-master。release 分支从 develop 分支 fork 出来，最终会合并到 develop 分支和 master 分支。合并到 master 分支上就是可以发布的代码了。有人可能会问那为什么合并回 develop 分支呢？很简单，有了 release 分支，那么相关的代码修复就只会在 release 分支上改动了，最后必然要合并到 develop 分支。下面细说。&nbsp;我们最初所有的开发工作都在 develop 分支上，当我们这一期的功能开发完毕的时候，我们基于 develop 分支开一个新的 release 分支。这个时候我们就可以对 release 分支做统一的测试了，另外做一些发布准备工作：比如版本号之类的。&nbsp;如果测试工作或者发布准备工作和具体的开发工作由不同人来做，比如国内的 RD 和 QA，这个 RD 就可以继续基于 develop 分支继续开发了。再或者说公司对于发布有严格的时间控制，开发工作提前并且完美的完成了，这个时候我们就可以在 develop 分支上继续我们下一期的开发了。同时如果测试有问题的话，我们将直接在 release 分支上修改，然后将修改合并到 develop 分支上。待所有的测试和准备工作做完之后，我们就可以将 release 分支合并到 master 分支上，并进行发布了。&nbsp;一些相关命令如下。&nbsp;新建 release 分支&nbsp;$&nbsp;git&nbsp;checkout&nbsp;-b&nbsp;release-1.2&nbsp;developSwitched&nbsp;to&nbsp;a&nbsp;new&nbsp;branch&nbsp;“release-1.2”$&nbsp;./bump-version.sh&nbsp;1.2File modified&nbsp;successfully,&nbsp;version bumped&nbsp;to&nbsp;1.2.$&nbsp;git&nbsp;commit&nbsp;-a&nbsp;-m&nbsp;“Bumped version number to 1.2”[release-1.2&nbsp;74d9424]&nbsp;Bumped version number&nbsp;to&nbsp;1.21&nbsp;files&nbsp;changed,&nbsp;1&nbsp;insertions(+),&nbsp;1&nbsp;deletions(-)&nbsp;release 分支合并到 master 分支&nbsp;$&nbsp;git checkout masterSwitched&nbsp;to&nbsp;branch&nbsp;‘master’$&nbsp;git&nbsp;merge&nbsp;–no-ff&nbsp;release-1.2Merge made by&nbsp;recursive.(Summary of&nbsp;changes)$&nbsp;git&nbsp;tag&nbsp;-a&nbsp;1.2&nbsp;release 分支合并到 develop 分支&nbsp;$&nbsp;git checkout developSwitched&nbsp;to&nbsp;branch&nbsp;‘develop’$&nbsp;git&nbsp;merge&nbsp;–no-ff&nbsp;release-1.2Merge made by&nbsp;recursive.(Summary of&nbsp;changes)&nbsp;最后，删除 release 分支&nbsp;$&nbsp;git&nbsp;branch&nbsp;-d&nbsp;release-1.2Deleted branch&nbsp;release-1.2&nbsp;(was&nbsp;ff452fe).&nbsp;4.3 Hotfix 分支&nbsp;顾名思义，hotfix 分支用来修复线上 bug。当线上代码出现 bug 时，我们基于 master 分支开一个 hotfix 分支，修复 bug 之后再将 hotfix 分支合并到 master 分支并进行发布，同时 develop 分支作为最新最全的代码分支，hotfix 分支也需要合并到 develop 分支上去。仔细想一想，其实 hotfix 分支和 release 分支功能类似。hotfix 的好处是不打断 develop 分支正常进行，同时对于现实代码的修复貌似也没有更好的方法了（总不能直接修改 master 代码吧:D）。&nbsp;&nbsp;&nbsp;一些相关的命令。&nbsp;新建 hotfix 分支&nbsp;$&nbsp;git&nbsp;checkout&nbsp;-b&nbsp;hotfix-1.2.1&nbsp;masterSwitched&nbsp;to&nbsp;a&nbsp;new&nbsp;branch&nbsp;“hotfix-1.2.1”$&nbsp;./bump-version.sh&nbsp;1.2.1Files modified&nbsp;successfully,&nbsp;version bumped&nbsp;to&nbsp;1.2.1.$&nbsp;git&nbsp;commit&nbsp;-a&nbsp;-m&nbsp;“Bumped version number to 1.2.1”[hotfix-1.2.1&nbsp;41e61bb]&nbsp;Bumped version number&nbsp;to&nbsp;1.2.11&nbsp;files&nbsp;changed,&nbsp;1&nbsp;insertions(+),&nbsp;1&nbsp;deletions(-)&nbsp;Fix bug&nbsp;$&nbsp;git&nbsp;commit&nbsp;-m&nbsp;“Fixed severe production problem”[hotfix-1.2.1&nbsp;abbe5d6]&nbsp;Fixed severe production&nbsp;problem5&nbsp;files&nbsp;changed,&nbsp;32&nbsp;insertions(+),&nbsp;17&nbsp;deletions(-)&nbsp;buf fix 之后，hotfix 合并到 master&nbsp;$&nbsp;git checkout masterSwitched&nbsp;to&nbsp;branch&nbsp;‘master’$&nbsp;git&nbsp;merge&nbsp;–no-ff&nbsp;hotfix-1.2.1Merge made by&nbsp;recursive.(Summary of&nbsp;changes)$&nbsp;git&nbsp;tag&nbsp;-a&nbsp;1.2.1&nbsp;hotfix 合并到 develop 分支&nbsp;$&nbsp;git checkout developSwitched&nbsp;to&nbsp;branch&nbsp;‘develop’$&nbsp;git&nbsp;merge&nbsp;–no-ff&nbsp;hotfix-1.2.1Merge made by&nbsp;recursive.(Summary of&nbsp;changes)&nbsp;删除 hotfix 分支&nbsp;$&nbsp;git&nbsp;branch&nbsp;-d&nbsp;hotfix-1.2.1Deleted branch&nbsp;hotfix-1.2.1&nbsp;(was&nbsp;abbe5d6).]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的猴子补丁monkey patch]]></title>
    <url>%2F2018%2F12%2F12%2Fpython-monkey-patch%2F</url>
    <content type="text"><![CDATA[monkey patch指的是在运行时动态替换,一般是在startup的时候.用过gevent就会知道,会在最开头的地方gevent.monkey.patch_all();把标准库中的thread/socket等给替换掉.这样我们在后面使用socket的时候可以跟平常一样使用,无需修改任何代码,但是它变成非阻塞的了.一个比较实用的例子，很多代码用到 import json，后来发现ujson性能更高，如果觉得把每个文件的import json 改成 import ujson as json成本较高，或者说想测试一下用ujson替换json是否符合预期，只需要在入口加上：import json import ujson def monkey_patch_json(): json.__name__ = &apos;ujson&apos; json.dumps = ujson.dumps json.loads = ujson.loads monkey_patch_json() 最后,注意不能单纯的json = ujson来替换.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
</search>
